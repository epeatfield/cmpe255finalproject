{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##Read in data\n",
    "storms = pd.read_csv('StormEvents_details-ftp_v1.0_d2018_c20181017.csv.gz', compression='gzip', header=0)\n",
    "weather = pd.read_csv('1531535.csv', header=0, error_bad_lines=False, low_memory=False)\n",
    "##Remove some unwanted columns\n",
    "weather = weather.drop(weather.columns[[28,30,31,32,33,35,36,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89]], axis=1)\n",
    "weather = weather.drop(weather.columns[[6,7,9]], axis=1)\n",
    "##add location columns to weather\n",
    "weather['COUNTY'] = np.nan\n",
    "weather['ST'] = np.nan\n",
    "weather.rename(columns={'STATION': 'WBAN'}, inplace=True)\n",
    "weather['STATION_NAME'] = weather['STATION_NAME'].astype(str).str[:-5]\n",
    "weather['WBAN'] = weather['WBAN'].str[5:].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read in data for stations and their locations\n",
    "locs = pd.read_fwf('emshr_lite_201810.txt', skiprows=[1], header=0)\n",
    "locs = locs[locs.CTRY_NAME == 'UNITED STATES'].reset_index(drop=True)\n",
    "col_list = ['WBAN', 'COUNTY', 'ST']\n",
    "locs = locs[col_list]\n",
    "locs = locs[pd.notnull(locs['COUNTY'])].reset_index(drop=True)\n",
    "locs = locs[pd.notnull(locs['WBAN'])].reset_index(drop=True)\n",
    "locs = locs[pd.notnull(locs['ST'])].reset_index(drop=True)\n",
    "locs['WBAN'] = locs['WBAN'].astype(str).str[:-2].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.merge(weather, locs, on=['WBAN']) ###Merge station location data with weather based on WBAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "storms.rename(columns={'CZ_NAME': 'COUNTY'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type = storms['EVENT_TYPE'].unique() ##add event ID\n",
    "event_type = pd.DataFrame(data=event_type, columns=['Weather']) ##Create table for the different types of storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type['EventID'] = event_type.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "storms = storms[storms.CZ_TYPE == 'C'].reset_index(drop=True) ##Only compare storms by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ADD STATE COLUMN TO RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = weather_data[pd.notnull(weather_data['COUNTY_y'])].reset_index(drop=True)\n",
    "weather_data = weather_data[pd.notnull(weather_data['ST_y'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###REMOVE COUNTY X and ST X\n",
    "weather_data = weather_data.drop(weather_data.columns[[29,30]], axis=1)\n",
    "weather_data.rename(columns={'COUNTY_y': 'COUNTY'}, inplace=True)\n",
    "weather_data.rename(columns={'ST_y': 'ST'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REFORMAT DATE AND TIME DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['year'] = np.nan\n",
    "weather_data['BEGIN_DAY'] = np.nan\n",
    "weather_data['start_time'] = np.nan\n",
    "weather_data['month'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##split date into date and time, save time as time\n",
    "f = lambda x: x[\"DATE\"].rsplit(\" \", 1)[1]\n",
    "weather_data[\"start_time\"] = weather_data.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##split date to get day month year\n",
    "f2 = lambda x: x[\"DATE\"].rsplit(\" \", 1)[0]\n",
    "weather_data[\"BEGIN_DAY\"] = weather_data.apply(f2, axis=1)\n",
    "weather_data[\"year\"] = weather_data.apply(f2, axis=1)\n",
    "weather_data[\"month\"] = weather_data.apply(f2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = lambda x: x[\"BEGIN_DAY\"].split(\"/\", 2)[1]\n",
    "weather_data[\"BEGIN_DAY\"] = weather_data.apply(f3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4 = lambda x: x[\"year\"].split(\"/\", 2)[2]\n",
    "f5 = lambda x: x['month'].split(\"/\",2)[0]\n",
    "weather_data['year'] = weather_data.apply(f4, axis=1)\n",
    "weather_data['month'] = weather_data.apply(f5, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in zeroes at front\n",
    "weather_data['month'] = weather_data['month'].apply(lambda x: x.zfill(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##combine month and year\n",
    "weather_data[\"BEGIN_YEARMONTH\"] = weather_data[\"year\"].map(str) + weather_data[\"month\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del weather_data['DATE']\n",
    "del weather_data['year']\n",
    "del weather_data['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove colon\n",
    "d = lambda x: x['start_time'].replace(':','')\n",
    "weather_data['start_time'] = weather_data.apply(d, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###drop monthly columns\n",
    "states = pd.read_csv('states.csv', delimiter=',', header=0)\n",
    "weather_data = pd.merge(weather_data, states, on=['ST'])\n",
    "weather_data['STATE'] = weather_data['STATE'].str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['end_time'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['end_time'] = weather_data['start_time'].astype(int) + 100 ##add end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now if END_TIME > 2399, subtract 2400\n",
    "test = weather_data.end_time > 2399\n",
    "column_name = 'end_time'\n",
    "weather_data.loc[test, column_name] -= 2400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['end_time'] = weather_data['end_time'].astype(str).apply(lambda x: x.zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weather_data['COUNTY'] = weather_data['COUNTY'].apply(str)\n",
    "weather_data['STATE'] = weather_data['STATE'].apply(str)\n",
    "weather_data['BEGIN_YEARMONTH'] = weather_data['BEGIN_YEARMONTH'].apply(int)\n",
    "weather_data['BEGIN_DAY'] = weather_data['BEGIN_DAY'].apply(int)\n",
    "weather_data['start_time'] = weather_data['start_time'].apply(int)\n",
    "weather_data['end_time'] = weather_data['end_time'].apply(int)\n",
    "\n",
    "storms['COUNTY'] = storms['COUNTY'].apply(str)\n",
    "storms['STATE'] = storms['STATE'].apply(str)\n",
    "storms['BEGIN_YEARMONTH'] = storms['BEGIN_YEARMONTH'].apply(int)\n",
    "storms['BEGIN_DAY'] = storms['BEGIN_DAY'].apply(int)\n",
    "storms['BEGIN_TIME'] = storms['BEGIN_TIME'].apply(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(weather_data, storms, on=['COUNTY', 'STATE','BEGIN_YEARMONTH', 'BEGIN_DAY']) ###merge columns based on county, state, yearmonth, day, and time range (starttime is between the weather_data range)\n",
    "##merge storm and weather based on county, state, month, day, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##only keep times that fall between start time and end time\n",
    "final = final[(final.start_time <= final.BEGIN_TIME) & (final.BEGIN_TIME <= final.end_time)] #filter via boolean series index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to csv to check data\n",
    "#final.to_csv(path_or_buf='testout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Remove Duplicates\n",
    "final = final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop_duplicates(subset=['EVENT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
